{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kings\\miniconda3\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy  as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import gradio as gr\n",
    "\n",
    "# visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live WebCam Demo Inception-V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\kings/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Inception3(\n",
       "  (Conv2d_1a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2b_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (Conv2d_3b_1x1): BasicConv2d(\n",
       "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_4a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (Mixed_5b): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5c): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5d): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6a): InceptionB(\n",
       "    (branch3x3): BasicConv2d(\n",
       "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6b): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6c): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6d): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6e): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (AuxLogits): InceptionAux(\n",
       "    (conv0): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv1): BasicConv2d(\n",
       "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       "  )\n",
       "  (Mixed_7a): InceptionD(\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7b): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7c): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=2048, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 3)\n",
    "state_dict = torch.load(r\"C:\\Users\\kings\\OneDrive - MMU\\MSC DATA SCIENCE\\MSC Project\\models\\Inception3_Adamproposed_augmediapipe.pt\")\n",
    "\n",
    "model.load_state_dict(state_dict)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_emotion(file_path):\n",
    "\n",
    "    font_scale = 1.5\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    \n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open webcam\")\n",
    "    result_data = []\n",
    "    \n",
    "    while True:\n",
    "        # Capture a frame\n",
    "        ret, frame = cap.read()\n",
    "        facedet = cv2.CascadeClassifier(r'C:\\Users\\kings\\OneDrive - MMU\\MSC DATA SCIENCE\\MSC Project\\Msc-Project\\haarcascades\\haarcascade_frontalface_default.xml')\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = facedet.detectMultiScale(gray_frame, 1.1, 4)\n",
    "\n",
    "        if len(faces) == 0:\n",
    "            print(\"No faces detected in the frame\")\n",
    "            continue  # Skip processing this frame if no faces are detected\n",
    "\n",
    "        for x, y, w, h in faces:\n",
    "            roi_gray = gray_frame[y:y+h, x:x+w]\n",
    "            roi_color = frame[y:y+h, x:x+w]\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "            facess = facedet.detectMultiScale(roi_gray)\n",
    "            if len(facess) == 0:\n",
    "                print(\"Face not detected\")\n",
    "            else:\n",
    "                for (ex, ey, ew, eh) in facess:\n",
    "                    face_roi = roi_color[ey:ey+eh, ex:ex+ew]  # cropping the face\n",
    "\n",
    "        rgb_image = cv2.cvtColor(gray_frame, cv2.COLOR_GRAY2RGB)\n",
    "        image = cv2.resize(rgb_image, (299, 299))\n",
    "        image = image / 255.0  # normalization\n",
    "        data = torch.from_numpy(image)\n",
    "        data = data.type(torch.FloatTensor)\n",
    "        data = data.to(device)\n",
    "        reshaped_data = data.permute(2, 0, 1)  # Reshape the tensor to have 3 as the first dimension\n",
    "        reshaped_data = reshaped_data.unsqueeze(0)  # add a fourth dimension\n",
    "        outputs = model(reshaped_data)\n",
    "        pred = F.softmax(outputs[0], dim=-1)\n",
    "        final_pred = torch.argmax(pred, 0)\n",
    "\n",
    "        if final_pred == 0:\n",
    "            emotion = \"Negative\"\n",
    "        elif final_pred == 1:\n",
    "            emotion = \"Neutral\"\n",
    "        else:\n",
    "            emotion = \"Positive\"\n",
    "\n",
    "        text_x, text_y = x, y - 10  # Adjust the position above the bounding box\n",
    "        cv2.putText(frame, emotion, (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "\n",
    "        conf, classes = torch.max(pred, -1)\n",
    "        emotion_id = [0, 1, 2]\n",
    "        class_dict = {0: 'Negative', 1: 'Neutral', 2: 'Positive'}\n",
    "        class_names = [class_dict[label] for label in emotion_id]\n",
    "        result_data.append({'Confidence':conf.item(),'max_confidence':pred.tolist(),'Emotion':class_names[classes.item()]})\n",
    "\n",
    "        # # Write the result to a CSV file\n",
    "        # with open('result.csv', mode='a', newline='') as file:\n",
    "        #     writer = csv.writer(file)\n",
    "        #     if file.tell() == 0:\n",
    "        #         writer.writerow(['Confidence', 'max_confidence', 'Emotion'])  # Write header only if the file is empty\n",
    "        #     writer.writerows(result_data)\n",
    "\n",
    "        cv2.imshow(\"Facial Expression Recognition\", frame)\n",
    "\n",
    "        if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return result_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predict_emotion(r\"C:\\Users\\kings\\OneDrive - MMU\\MSC DATA SCIENCE\\MSC Project\\datasets\\CASME2\\CASME2\\CASME2-RAW\\CASME2-RAW\\sub01\\EP19_06f.avi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Confidence': 0.9465426206588745,\n",
       "  'max_confidence': [0.9465426206588745,\n",
       "   0.050117842853069305,\n",
       "   0.003339516930282116],\n",
       "  'Emotion': 'Negative'},\n",
       " {'Confidence': 0.9426162838935852,\n",
       "  'max_confidence': [0.9426162838935852,\n",
       "   0.0537981316447258,\n",
       "   0.003585565835237503],\n",
       "  'Emotion': 'Negative'},\n",
       " {'Confidence': 0.9435549378395081,\n",
       "  'max_confidence': [0.9435549378395081,\n",
       "   0.052898358553647995,\n",
       "   0.00354670244269073],\n",
       "  'Emotion': 'Negative'},\n",
       " {'Confidence': 0.942773699760437,\n",
       "  'max_confidence': [0.942773699760437,\n",
       "   0.05353566259145737,\n",
       "   0.003690673504024744],\n",
       "  'Emotion': 'Negative'},\n",
       " {'Confidence': 0.9471259117126465,\n",
       "  'max_confidence': [0.9471259117126465,\n",
       "   0.04958953708410263,\n",
       "   0.0032845649402588606],\n",
       "  'Emotion': 'Negative'},\n",
       " {'Confidence': 0.945117712020874,\n",
       "  'max_confidence': [0.945117712020874,\n",
       "   0.05150369182229042,\n",
       "   0.003378533525392413],\n",
       "  'Emotion': 'Negative'},\n",
       " {'Confidence': 0.9467746615409851,\n",
       "  'max_confidence': [0.9467746615409851,\n",
       "   0.04988718777894974,\n",
       "   0.0033381637185811996],\n",
       "  'Emotion': 'Negative'},\n",
       " {'Confidence': 0.9436607360839844,\n",
       "  'max_confidence': [0.9436607360839844,\n",
       "   0.052546266466379166,\n",
       "   0.0037930230610072613],\n",
       "  'Emotion': 'Negative'},\n",
       " {'Confidence': 0.9414743781089783,\n",
       "  'max_confidence': [0.9414743781089783,\n",
       "   0.05484282970428467,\n",
       "   0.0036828177981078625],\n",
       "  'Emotion': 'Negative'},\n",
       " {'Confidence': 0.940792977809906,\n",
       "  'max_confidence': [0.940792977809906,\n",
       "   0.05559122934937477,\n",
       "   0.003615720896050334],\n",
       "  'Emotion': 'Negative'},\n",
       " {'Confidence': 0.9434056282043457,\n",
       "  'max_confidence': [0.9434056282043457,\n",
       "   0.053133536130189896,\n",
       "   0.0034608563873916864],\n",
       "  'Emotion': 'Negative'},\n",
       " {'Confidence': 0.9398310780525208,\n",
       "  'max_confidence': [0.9398310780525208,\n",
       "   0.05639825761318207,\n",
       "   0.003770650364458561],\n",
       "  'Emotion': 'Negative'},\n",
       " {'Confidence': 0.9450297951698303,\n",
       "  'max_confidence': [0.9450297951698303,\n",
       "   0.05153827741742134,\n",
       "   0.0034319323021918535],\n",
       "  'Emotion': 'Negative'},\n",
       " {'Confidence': 0.9427251815795898,\n",
       "  'max_confidence': [0.9427251815795898,\n",
       "   0.053624264895915985,\n",
       "   0.0036506475880742073],\n",
       "  'Emotion': 'Negative'},\n",
       " {'Confidence': 0.9432685375213623,\n",
       "  'max_confidence': [0.9432685375213623,\n",
       "   0.05319039151072502,\n",
       "   0.0035409932024776936],\n",
       "  'Emotion': 'Negative'},\n",
       " {'Confidence': 0.9436190128326416,\n",
       "  'max_confidence': [0.9436190128326416,\n",
       "   0.052875448018312454,\n",
       "   0.003505539847537875],\n",
       "  'Emotion': 'Negative'},\n",
       " {'Confidence': 0.9440473318099976,\n",
       "  'max_confidence': [0.9440473318099976,\n",
       "   0.052468981593847275,\n",
       "   0.0034837631974369287],\n",
       "  'Emotion': 'Negative'},\n",
       " {'Confidence': 0.9463465809822083,\n",
       "  'max_confidence': [0.9463465809822083,\n",
       "   0.050134144723415375,\n",
       "   0.003519352525472641],\n",
       "  'Emotion': 'Negative'},\n",
       " {'Confidence': 0.9399021863937378,\n",
       "  'max_confidence': [0.9399021863937378,\n",
       "   0.05629608780145645,\n",
       "   0.0038018235936760902],\n",
       "  'Emotion': 'Negative'},\n",
       " {'Confidence': 0.9434059262275696,\n",
       "  'max_confidence': [0.9434059262275696,\n",
       "   0.053190771490335464,\n",
       "   0.0034033097326755524],\n",
       "  'Emotion': 'Negative'},\n",
       " {'Confidence': 0.9409892559051514,\n",
       "  'max_confidence': [0.9409892559051514,\n",
       "   0.0553024522960186,\n",
       "   0.0037082305643707514],\n",
       "  'Emotion': 'Negative'},\n",
       " {'Confidence': 0.942757785320282,\n",
       "  'max_confidence': [0.942757785320282,\n",
       "   0.053700968623161316,\n",
       "   0.0035413175355643034],\n",
       "  'Emotion': 'Negative'},\n",
       " {'Confidence': 0.9415345788002014,\n",
       "  'max_confidence': [0.9415345788002014,\n",
       "   0.05474986508488655,\n",
       "   0.0037156131584197283],\n",
       "  'Emotion': 'Negative'},\n",
       " {'Confidence': 0.9386703968048096,\n",
       "  'max_confidence': [0.9386703968048096,\n",
       "   0.057587333023548126,\n",
       "   0.0037423535250127316],\n",
       "  'Emotion': 'Negative'},\n",
       " {'Confidence': 0.942582368850708,\n",
       "  'max_confidence': [0.942582368850708,\n",
       "   0.05377116799354553,\n",
       "   0.003646427532657981],\n",
       "  'Emotion': 'Negative'},\n",
       " {'Confidence': 0.942049503326416,\n",
       "  'max_confidence': [0.942049503326416,\n",
       "   0.05415387451648712,\n",
       "   0.0037965080700814724],\n",
       "  'Emotion': 'Negative'},\n",
       " {'Confidence': 0.9416603446006775,\n",
       "  'max_confidence': [0.9416603446006775,\n",
       "   0.05482276901602745,\n",
       "   0.0035167899914085865],\n",
       "  'Emotion': 'Negative'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Confidence</th>\n",
       "      <th>max_confidence</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.946543</td>\n",
       "      <td>[0.9465426206588745, 0.050117842853069305, 0.0...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.942616</td>\n",
       "      <td>[0.9426162838935852, 0.0537981316447258, 0.003...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.943555</td>\n",
       "      <td>[0.9435549378395081, 0.052898358553647995, 0.0...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.942774</td>\n",
       "      <td>[0.942773699760437, 0.05353566259145737, 0.003...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.947126</td>\n",
       "      <td>[0.9471259117126465, 0.04958953708410263, 0.00...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.945118</td>\n",
       "      <td>[0.945117712020874, 0.05150369182229042, 0.003...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.946775</td>\n",
       "      <td>[0.9467746615409851, 0.04988718777894974, 0.00...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.943661</td>\n",
       "      <td>[0.9436607360839844, 0.052546266466379166, 0.0...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.941474</td>\n",
       "      <td>[0.9414743781089783, 0.05484282970428467, 0.00...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.940793</td>\n",
       "      <td>[0.940792977809906, 0.05559122934937477, 0.003...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.943406</td>\n",
       "      <td>[0.9434056282043457, 0.053133536130189896, 0.0...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.939831</td>\n",
       "      <td>[0.9398310780525208, 0.05639825761318207, 0.00...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.945030</td>\n",
       "      <td>[0.9450297951698303, 0.05153827741742134, 0.00...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.942725</td>\n",
       "      <td>[0.9427251815795898, 0.053624264895915985, 0.0...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.943269</td>\n",
       "      <td>[0.9432685375213623, 0.05319039151072502, 0.00...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.943619</td>\n",
       "      <td>[0.9436190128326416, 0.052875448018312454, 0.0...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.944047</td>\n",
       "      <td>[0.9440473318099976, 0.052468981593847275, 0.0...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.946347</td>\n",
       "      <td>[0.9463465809822083, 0.050134144723415375, 0.0...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.939902</td>\n",
       "      <td>[0.9399021863937378, 0.05629608780145645, 0.00...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.943406</td>\n",
       "      <td>[0.9434059262275696, 0.053190771490335464, 0.0...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.940989</td>\n",
       "      <td>[0.9409892559051514, 0.0553024522960186, 0.003...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.942758</td>\n",
       "      <td>[0.942757785320282, 0.053700968623161316, 0.00...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.941535</td>\n",
       "      <td>[0.9415345788002014, 0.05474986508488655, 0.00...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.938670</td>\n",
       "      <td>[0.9386703968048096, 0.057587333023548126, 0.0...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.942582</td>\n",
       "      <td>[0.942582368850708, 0.05377116799354553, 0.003...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.942050</td>\n",
       "      <td>[0.942049503326416, 0.05415387451648712, 0.003...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.941660</td>\n",
       "      <td>[0.9416603446006775, 0.05482276901602745, 0.00...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Confidence                                     max_confidence   Emotion\n",
       "0     0.946543  [0.9465426206588745, 0.050117842853069305, 0.0...  Negative\n",
       "1     0.942616  [0.9426162838935852, 0.0537981316447258, 0.003...  Negative\n",
       "2     0.943555  [0.9435549378395081, 0.052898358553647995, 0.0...  Negative\n",
       "3     0.942774  [0.942773699760437, 0.05353566259145737, 0.003...  Negative\n",
       "4     0.947126  [0.9471259117126465, 0.04958953708410263, 0.00...  Negative\n",
       "5     0.945118  [0.945117712020874, 0.05150369182229042, 0.003...  Negative\n",
       "6     0.946775  [0.9467746615409851, 0.04988718777894974, 0.00...  Negative\n",
       "7     0.943661  [0.9436607360839844, 0.052546266466379166, 0.0...  Negative\n",
       "8     0.941474  [0.9414743781089783, 0.05484282970428467, 0.00...  Negative\n",
       "9     0.940793  [0.940792977809906, 0.05559122934937477, 0.003...  Negative\n",
       "10    0.943406  [0.9434056282043457, 0.053133536130189896, 0.0...  Negative\n",
       "11    0.939831  [0.9398310780525208, 0.05639825761318207, 0.00...  Negative\n",
       "12    0.945030  [0.9450297951698303, 0.05153827741742134, 0.00...  Negative\n",
       "13    0.942725  [0.9427251815795898, 0.053624264895915985, 0.0...  Negative\n",
       "14    0.943269  [0.9432685375213623, 0.05319039151072502, 0.00...  Negative\n",
       "15    0.943619  [0.9436190128326416, 0.052875448018312454, 0.0...  Negative\n",
       "16    0.944047  [0.9440473318099976, 0.052468981593847275, 0.0...  Negative\n",
       "17    0.946347  [0.9463465809822083, 0.050134144723415375, 0.0...  Negative\n",
       "18    0.939902  [0.9399021863937378, 0.05629608780145645, 0.00...  Negative\n",
       "19    0.943406  [0.9434059262275696, 0.053190771490335464, 0.0...  Negative\n",
       "20    0.940989  [0.9409892559051514, 0.0553024522960186, 0.003...  Negative\n",
       "21    0.942758  [0.942757785320282, 0.053700968623161316, 0.00...  Negative\n",
       "22    0.941535  [0.9415345788002014, 0.05474986508488655, 0.00...  Negative\n",
       "23    0.938670  [0.9386703968048096, 0.057587333023548126, 0.0...  Negative\n",
       "24    0.942582  [0.942582368850708, 0.05377116799354553, 0.003...  Negative\n",
       "25    0.942050  [0.942049503326416, 0.05415387451648712, 0.003...  Negative\n",
       "26    0.941660  [0.9416603446006775, 0.05482276901602745, 0.00...  Negative"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kings\\miniconda3\\lib\\site-packages\\gradio\\routes.py\", line 427, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"c:\\Users\\kings\\miniconda3\\lib\\site-packages\\gradio\\blocks.py\", line 1323, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"c:\\Users\\kings\\miniconda3\\lib\\site-packages\\gradio\\blocks.py\", line 1051, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"c:\\Users\\kings\\miniconda3\\lib\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"c:\\Users\\kings\\miniconda3\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"c:\\Users\\kings\\miniconda3\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"C:\\Users\\kings\\AppData\\Local\\Temp\\ipykernel_20828\\3094263180.py\", line 8, in predict_emotion\n",
      "    raise IOError(\"Cannot open webcam\")\n",
      "OSError: Cannot open webcam\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kings\\miniconda3\\lib\\site-packages\\gradio\\routes.py\", line 427, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"c:\\Users\\kings\\miniconda3\\lib\\site-packages\\gradio\\blocks.py\", line 1323, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"c:\\Users\\kings\\miniconda3\\lib\\site-packages\\gradio\\blocks.py\", line 1051, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"c:\\Users\\kings\\miniconda3\\lib\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"c:\\Users\\kings\\miniconda3\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"c:\\Users\\kings\\miniconda3\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"C:\\Users\\kings\\AppData\\Local\\Temp\\ipykernel_20828\\3094263180.py\", line 15, in predict_emotion\n",
      "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
      "cv2.error: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "No faces detected in the frame\n",
      "Face not detected\n",
      "Face not detected\n",
      "No faces detected in the frame\n",
      "No faces detected in the frame\n",
      "No faces detected in the frame\n",
      "No faces detected in the frame\n",
      "No faces detected in the frame\n",
      "Face not detected\n",
      "No faces detected in the frame\n",
      "No faces detected in the frame\n",
      "No faces detected in the frame\n",
      "No faces detected in the frame\n",
      "No faces detected in the frame\n",
      "No faces detected in the frame\n",
      "Face not detected\n",
      "No faces detected in the frame\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks(gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\n",
    "    \"\"\"\n",
    "    Facial Expression Recognition\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    # condition = gr.Radio([\"New\", \"Used\"], label=\"Vehicle Condition\")\n",
    "    video = gr.Video()\n",
    "    generate_btn = gr.Button(\"Predict\")\n",
    "\n",
    "\n",
    "    generate_btn.click(fn=predict_emotion, inputs=video, outputs=)\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks(gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\n",
    "    \"\"\"\n",
    "    # Spotting facial expression in video sequences\n",
    "\n",
    "    \"\"\")\n",
    "     plot_type == \"multiline\":\n",
    "        source = data.stocks()\n",
    "\n",
    "        highlight = alt.selection(type='single', on='mouseover',\n",
    "                                fields=['symbol'], nearest=True)\n",
    "\n",
    "        base = alt.Chart(source).encode(\n",
    "            x='date:T',\n",
    "            y='price:Q',\n",
    "            color='symbol:N'\n",
    "        )\n",
    "\n",
    "        points = base.mark_circle().encode(\n",
    "            opacity=alt.value(0)\n",
    "        ).add_selection(\n",
    "            highlight\n",
    "        ).properties(\n",
    "            width=600\n",
    "        )\n",
    "\n",
    "        lines = base.mark_line().encode(\n",
    "            size=alt.condition(~highlight, alt.value(1), alt.value(3))\n",
    "        )\n",
    "\n",
    "        return points + lines\n",
    "    video = gr.Video(label='Upload your video here')\n",
    "    generate_btn = gr.Button(\"Predict emotions\")\n",
    "    output = gr.Text(label=\"predicted emotions\")\n",
    "\n",
    "    generate_btn.click(fn=predict_emotion, inputs=[video], outputs=output)\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
